{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57ceab-625f-4f0c-a126-0a6acee7342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1.You are work#ng on a mach#ne learn#ng project where you have a dataset conta#n#ng numer#cal and\n",
    "categor#cal features. You have #dent#f#ed that some of the features are h#ghly correlated and there are\n",
    "m#ss#ng values #n some of the columns. You want to bu#ld a p#pel#ne that automates the feature\n",
    "eng#neer#ng process and handles the m#ss#ng valuesD\n",
    "Des#gn a p#pel#ne that #ncludes the follow#ng steps\"\n",
    "Use an automated feature select#on method to #dent#fy the #mportant features #n the datasetC\n",
    "Create a numer#cal p#pel#ne that #ncludes the follow#ng steps\"\n",
    "Impute the m#ss#ng values #n the numer#cal columns us#ng the mean of the column valuesC\n",
    "Scale the numer#cal columns us#ng standard#sat#onC\n",
    "Create a categor#cal p#pel#ne that #ncludes the follow#ng steps\"\n",
    "Impute the m#ss#ng values #n the categor#cal columns us#ng the most frequent value of the columnC\n",
    "One-hot encode the categor#cal columnsC\n",
    "Comb#ne the numer#cal and categor#cal p#pel#nes us#ng a ColumnTransformerC\n",
    "Use a Random Forest Class#f#er to bu#ld the f#nal modelC\n",
    "Evaluate the accuracy of the model on the test datasetD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9ebf33-c298-4b8a-a5de-802df9c6ea05",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q.2 Ans-\n",
    "       \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Create pipelines for the individual classifiers\n",
    "rf_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "lr_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Create the voting classifier\n",
    "voting_classifier = VotingClassifier(\n",
    "    estimators=[('rf', rf_pipeline), ('lr', lr_pipeline)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "# Train the pipeline on the data\n",
    "voting_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy on the test set\n",
    "accuracy = voting_classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "In this example, we create separate pipelines for the Random Forest Classifier and the Logistic Regression Classifier, each including any necessary preprocessing steps such as imputation, scaling, and one-hot encoding. We then create a Voting Classifier that combines the predictions of these two classifiers using a soft voting strategy, which takes the predicted probabilities and averages them to make a final prediction.\n",
    "\n",
    "We train the entire pipeline on the training data and evaluate its accuracy on the test set. The final accuracy score can be used to assess the performance of the ensemble classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
