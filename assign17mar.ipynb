{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d85bea3d-6dc9-43e9-9153-ae7eb0d7d9d3",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b81f48-6f7b-4a62-a084-e899c86e5e98",
   "metadata": {},
   "source": [
    "##  Missing data is defined as the values or data that is not stored (or not present) for some variable/s in the given dataset. Below is a sample of the missing data from the Titanic dataset. You can see the columns 'Age' and 'Cabin' have some missing values.\n",
    "\n",
    "## Missing values can pose a significant challenge in data analysis, as they can: Reduce the sample size: This can decrease the accuracy and reliability of your analysis. Introduce bias: If the missing data is not handled properly, it can bias the results of your analysis.\n",
    "\n",
    "## All the machine learning algorithms don't support missing values but some ML algorithms are robust to missing values in the dataset. The k-NN algorithm can ignore a column from a distance measure when a value is missing. Naive Bayes can also support missing values when making a prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f00d45-be95-47eb-accd-3d11164c3414",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c26845-9b82-4acf-90a9-97881fb9f6a2",
   "metadata": {},
   "source": [
    "##  List of Methods to handle missing values in a dataset\n",
    "## Deleting the Missing Values.\n",
    "## Imputing the Missing Values.\n",
    "## Imputing the Missing Values for Categorical Features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1e486a0-7c99-46ad-85e4-659bbb5b1f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "df=sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d10a1213-facc-44a4-82a7-b4924b1815b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
       "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
       "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
       "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
       "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
       "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
       "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
       "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
       "888         0       3  female   NaN      1      2  23.4500        S   Third   \n",
       "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
       "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "0      man        True  NaN  Southampton    no  False  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "2    woman       False  NaN  Southampton   yes   True  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "4      man        True  NaN  Southampton    no   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "886    man        True  NaN  Southampton    no   True  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "888  woman       False  NaN  Southampton    no  False  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "890    man        True  NaN   Queenstown    no   True  \n",
       "\n",
       "[891 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63175fb0-bab4-4aa9-82e3-c2bdcd41b3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.dropna()\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a14e71c-dcf5-4639-af85-2c2cd4cc6949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>E</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>child</td>\n",
       "      <td>False</td>\n",
       "      <td>G</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>D</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "1           1       1  female  38.0      1      0  71.2833        C  First   \n",
       "3           1       1  female  35.0      1      0  53.1000        S  First   \n",
       "6           0       1    male  54.0      0      0  51.8625        S  First   \n",
       "10          1       3  female   4.0      1      1  16.7000        S  Third   \n",
       "11          1       1  female  58.0      0      0  26.5500        S  First   \n",
       "..        ...     ...     ...   ...    ...    ...      ...      ...    ...   \n",
       "871         1       1  female  47.0      1      1  52.5542        S  First   \n",
       "872         0       1    male  33.0      0      0   5.0000        S  First   \n",
       "879         1       1  female  56.0      0      1  83.1583        C  First   \n",
       "887         1       1  female  19.0      0      0  30.0000        S  First   \n",
       "889         1       1    male  26.0      0      0  30.0000        C  First   \n",
       "\n",
       "       who  adult_male deck  embark_town alive  alone  \n",
       "1    woman       False    C    Cherbourg   yes  False  \n",
       "3    woman       False    C  Southampton   yes  False  \n",
       "6      man        True    E  Southampton    no   True  \n",
       "10   child       False    G  Southampton   yes  False  \n",
       "11   woman       False    C  Southampton   yes   True  \n",
       "..     ...         ...  ...          ...   ...    ...  \n",
       "871  woman       False    D  Southampton   yes  False  \n",
       "872    man        True    B  Southampton    no   True  \n",
       "879  woman       False    C    Cherbourg   yes  False  \n",
       "887  woman       False    B  Southampton   yes   True  \n",
       "889    man        True    C    Cherbourg   yes   True  \n",
       "\n",
       "[182 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14937344-edc3-4342-93ad-e1b0b394c08e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "0           0       3    male  22.0      1      0   7.2500        S   Third   \n",
      "1           1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2           1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3           1       1  female  35.0      1      0  53.1000        S   First   \n",
      "4           0       3    male  35.0      0      0   8.0500        S   Third   \n",
      "..        ...     ...     ...   ...    ...    ...      ...      ...     ...   \n",
      "886         0       2    male  27.0      0      0  13.0000        S  Second   \n",
      "887         1       1  female  19.0      0      0  30.0000        S   First   \n",
      "888         0       3  female  28.0      1      2  23.4500        S   Third   \n",
      "889         1       1    male  26.0      0      0  30.0000        C   First   \n",
      "890         0       3    male  32.0      0      0   7.7500        Q   Third   \n",
      "\n",
      "       who  adult_male deck  embark_town alive  alone  survived\\t  \n",
      "0      man        True  NaN  Southampton    no  False           0  \n",
      "1    woman       False    C    Cherbourg   yes  False           1  \n",
      "2    woman       False  NaN  Southampton   yes   True           1  \n",
      "3    woman       False    C  Southampton   yes  False           1  \n",
      "4      man        True  NaN  Southampton    no   True           0  \n",
      "..     ...         ...  ...          ...   ...    ...         ...  \n",
      "886    man        True  NaN  Southampton    no   True           0  \n",
      "887  woman       False    B  Southampton   yes   True           1  \n",
      "888  woman       False  NaN  Southampton    no  False           0  \n",
      "889    man        True    C    Cherbourg   yes   True           1  \n",
      "890    man        True  NaN   Queenstown    no   True           0  \n",
      "\n",
      "[891 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['fare'] = df['fare'].fillna(df['fare'].mean()) \n",
    "\n",
    "# replacing missing values in price column \n",
    "# with median of that column \n",
    "df['age'] = df['age'].fillna(df['age'].median()) \n",
    "\n",
    "# replacing missing values in bought column with \n",
    "# standard deviation of that column \n",
    "df['survived\t'] = df['survived'].fillna(df['survived'].std()) \n",
    "\n",
    "\n",
    "\n",
    "print(df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca94bf7d-987b-411c-9712-4e80fe77976e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  SocialApps\n",
      "0   facebook\n",
      "1   whatsapp\n",
      "2  instagram\n",
      "3   facebook\n",
      "4        NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Creating dataset\n",
    "data = pd.DataFrame({'SocialApps':['facebook', 'whatsapp', \n",
    "      'instagram', 'facebook', np.nan]})\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27a040d-6780-4fb6-a641-a157cf04a42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     facebook\n",
      "1     whatsapp\n",
      "2    instagram\n",
      "3     facebook\n",
      "4     facebook\n",
      "Name: SocialApps, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Creating a SimpleImputer object\n",
    "imp = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "\"\"\"\" Impute the missing values in the 'SocialApps' \n",
    "    column of the 'data' DataFrame\"\"\"\n",
    "\n",
    "# Fitting transform\n",
    "data['SocialApps'] = imp.fit_transform(data[['SocialApps']])\n",
    "\n",
    "#Printing result\n",
    "print(data['SocialApps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70a9a76-7263-489c-837c-02aba73f866f",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517477f3-d4cf-436a-b5ac-ecff9db7f04b",
   "metadata": {},
   "source": [
    "## Imbalanced data sets are a special case for classification problem where the class distribution is not uniform among the classes. Typically, they are composed by two classes: The majority (negative) class and the minority (positive) class [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c29199-3be2-4e4a-b601-15e233364679",
   "metadata": {},
   "source": [
    "## Potential Poor Performance on Majority Class.\n",
    "## Undersampling may lead to a model that performs poorly on the majority class since it has less information to learn from. This can result in misclassification of the majority class instances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98e80fe-387a-4201-ac54-0310035785cc",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down-sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c793c06-353d-428b-a3bd-400f3053a6a8",
   "metadata": {},
   "source": [
    "## Two types of resampling are Up-sampling and Down-sampling: After this process, the counts of both labels are almost the same.\n",
    "## Upsampling: Upsampling is a procedure where synthetically generated data points (corresponding to minority class) are injected into the dataset. Where you increase the frequency of the samples, such as from minutes to seconds.\n",
    "## Downsampling:This is done by systematically selecting a subset of the data at a lower rate than the original. The main goal of downsampling is to reduce the computational requirements, storage needs, and potentially noise in your data. Where you decrease the frequency of the samples, such as from days to months."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03046765-1471-4526-beff-fad1fd6930a7",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc26fbc-b7e0-4d3b-903a-ce7aa5cb5ee1",
   "metadata": {},
   "source": [
    "## Data augmentation is the process of artificially generating new data from existing data, primarily to train new machine learning (ML) models.\n",
    "\n",
    "## SMOTE: Synthetic Minority Oversampling Technique\n",
    "## SMOTE is an oversampling technique where the synthetic samples are generated for the minority class. This algorithm helps to overcome the overfitting problem posed by random oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5cba7ba-dbf4-48e0-809e-58a47a911c0d",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c890e6b9-e064-45df-8b02-67b2a0cc92ab",
   "metadata": {},
   "source": [
    "## An outlier is a data point that is significantly different from the other data points in a dataset. Its value is mostly unexpected and deviates a lot from the mean of the dataset. The task of outlier detection is to detect these points.\n",
    "\n",
    "## It is essential to detect and handle outliers appropriately to ensure the accuracy and validity of machine learning models. Outliers can provide valuable insights into the data, but they can also lead to biased or incorrect results if not handled appropriately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b6a4dc-d62a-4af8-a8bc-ae65edda1262",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06941e2-2ab2-4515-b256-30e902dda837",
   "metadata": {},
   "source": [
    "\n",
    "## Mean imputation: Replace missing values with the mean of the variable.\n",
    "## Median imputation: Replace missing values with the median of the variable.\n",
    "## Mode imputation: Replace missing values with the most frequent value of the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d32473-cf49-4223-a2cd-485c77813ce1",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac88937-9d19-4727-80a5-96ba8dfeae63",
   "metadata": {},
   "source": [
    "## Methods for identifying missing data\n",
    "## There are multiple methods that can be used to identify missing data in pandas. Below are the most recurrent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18553531-10e7-4120-a9a2-4d99b374578a",
   "metadata": {},
   "source": [
    "## .isnull() :This function returns a pandas dataframe, where each value is a boolean value True if the value is missing, False otherwise.\n",
    "\n",
    "## .notnull() :Similarly to the previous function, the values for this one are False if either NaN or None value is detected.\n",
    "\n",
    "## .info() :This function generates three main columns, including the “Non-Null Count” which shows the number of non-missing values for each column.\n",
    "\n",
    "## .isna() :This one is similar to isnull and notnull. However it shows True only when the missing value is NaN type. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1710894-c227-4e87-b838-a25aa503b981",
   "metadata": {},
   "source": [
    "## Choosing the right imputation method based on the type of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1c2c47-2b9c-4658-9dbc-f84078d49676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame({\"Type of missing data\": [\"Missing Completely At Random\",\"Missing At Random\",\"Missing Not At Random\"],\n",
    "                 \"Imputation method\":[\"Mean, Median, Mode, or any other imputation method\",\n",
    "                    \"Multiple imputation ,Regression imputation\",\"Pattern Substitution, Maximum Likelihood estimation\"]})\n",
    "                \n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "976b1d4c-bfe1-488f-834f-39e9084e4ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type of missing data</th>\n",
       "      <th>Imputation method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing Completely At Random</td>\n",
       "      <td>Mean, Median, Mode, or any other imputation me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missing At Random</td>\n",
       "      <td>Multiple imputation ,Regression imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Missing Not At Random</td>\n",
       "      <td>Pattern Substitution, Maximum Likelihood estim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Type of missing data  \\\n",
       "0  Missing Completely At Random   \n",
       "1             Missing At Random   \n",
       "2         Missing Not At Random   \n",
       "\n",
       "                                   Imputation method  \n",
       "0  Mean, Median, Mode, or any other imputation me...  \n",
       "1         Multiple imputation ,Regression imputation  \n",
       "2  Pattern Substitution, Maximum Likelihood estim...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18c8ebd-1bd2-4301-ac41-eb5cb94e13d4",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79884bba-3bf2-4fe1-b7b0-a48042591be6",
   "metadata": {},
   "source": [
    "##  To manage class imbalance in a dataset, techniques such as SMOTE, Random Undersampling, and Cross-Validation, along with stratified random sampling, can be used to balance the dataset and minimize selection biases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f238596-8779-4f67-9adb-da4bacf7a34b",
   "metadata": {},
   "source": [
    "## A widely adopted and perhaps the most straightforward method for dealing with highly imbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling).\n",
    "\n",
    "## In this project, majority of patients in the dataset do not have the condition of interest, while a small percentage do. Here we go with the resampling method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990893e8-fb17-4078-85e6-299c0ca99d7b",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282c9ac6-ab3e-45c7-87d0-17471bc0e947",
   "metadata": {},
   "source": [
    "## Methods you can employ to balance the dataset and down sample the majority class\n",
    "## Resampling (Oversampling and Undersampling)\n",
    "\n",
    "## This technique is used to upsample or downsample the minority or majority class. When we are using an imbalanced dataset, we can oversample the minority class using replacement. This technique is called oversampling.\n",
    "\n",
    "## In this project, The dataset is unbalanced, with the bulk of customers reporting being satisfied. We can oversample the customers data who are not satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f39ade9-3abd-4104-9b3a-f2cfe78350e4",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6962cfb9-cefb-4d8a-9b39-ab251ce5c76e",
   "metadata": {},
   "source": [
    "##  The dataset is unbalanced with a low percentage of occurrences while working on a project that requires to estimate the occurrence of a rare event.\n",
    "\n",
    "## We can deal with the oversmpling method to balance the dataset and up-sample the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8101991-7588-4da7-873a-164d00b6f639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
